{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Evaluation â€” 4-Axis Metrics & Attention Maps\n",
        "\n",
        "Load trained model and validation data. Compute exact match, tree edit similarity, compilation success, and plot attention heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Clone repo on Colab ---\n",
        "import os\n",
        "if not os.path.exists(\"/content/DeepPTX\"):\n",
        "    !git clone https://github.com/ns-1456/DeepPTX.git /content/DeepPTX\n",
        "%cd /content/DeepPTX\n",
        "\n",
        "!pip install -q tqdm pyarrow\n",
        "\n",
        "import sys\n",
        "REPO_ROOT = \"/content/DeepPTX\" if os.path.exists(\"/content/DeepPTX\") else os.path.abspath(\"..\")\n",
        "if REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, REPO_ROOT)\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from ptx_decompiler.model import PTXDecompilerModel\n",
        "from ptx_decompiler.tokenizer import PTXTokenizer, ASTTokenizer\n",
        "from ptx_decompiler.data import normalize_ptx, ast_to_cuda\n",
        "from ptx_decompiler.data.compiler import compile_cuda_to_ptx_silent\n",
        "from ptx_decompiler.training.metrics import exact_match_accuracy, compute_tree_edit_distance, compile_success_rate\n",
        "print(\"Imports OK\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/NeuralPTX/dataset_100k.parquet\"\n",
        "CKPT_PATH = \"/content/drive/MyDrive/NeuralPTX/checkpoints/checkpoint_epoch_29.pt\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = pd.read_parquet(DATA_PATH)\n",
        "ptx_tok = PTXTokenizer(max_vocab_size=2000)\n",
        "ptx_tok.build_vocab(df[\"ptx_normalized\"].tolist())\n",
        "ast_tok = ASTTokenizer()\n",
        "\n",
        "ptx_to_ast = torch.full((len(ptx_tok),), -1, dtype=torch.long)\n",
        "for t, pid in ptx_tok.vocab.items():\n",
        "    if t in ast_tok.vocab:\n",
        "        ptx_to_ast[pid] = ast_tok.vocab[t]\n",
        "\n",
        "model = PTXDecompilerModel(\n",
        "    ptx_vocab_size=len(ptx_tok),\n",
        "    ast_vocab_size=len(ast_tok),\n",
        "    ptx_to_ast_map=ptx_to_ast,\n",
        ").to(DEVICE)\n",
        "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
        "model.load_state_dict(ckpt[\"model\"])\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ptx_decompiler.data.dataset import PTXASTDataset, collate_pad_batch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "val_df = df.sample(frac=0.1, random_state=42)\n",
        "val_ds = PTXASTDataset(\n",
        "    ptx_strings=val_df[\"ptx_normalized\"].tolist(),\n",
        "    ast_strings=val_df[\"ast_sexp\"].tolist(),\n",
        "    ptx_tokenizer=ptx_tok,\n",
        "    ast_tokenizer=ast_tok,\n",
        "    tiers=val_df[\"tier\"].tolist(),\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=64,\n",
        "    collate_fn=lambda b: collate_pad_batch(b, ptx_tok.pad_id, ast_tok.pad_id),\n",
        ")\n",
        "\n",
        "em_sum, ted_sum, n = 0.0, 0.0, 0\n",
        "pbar = tqdm(val_loader, desc=\"Evaluating\", unit=\"batch\",\n",
        "            bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}\")\n",
        "for batch in pbar:\n",
        "    ptx = batch[\"ptx_ids\"].to(DEVICE)\n",
        "    ast_in = batch[\"ast_input_ids\"].to(DEVICE)\n",
        "    ast_tgt = batch[\"ast_target_ids\"]\n",
        "    pad_mask = (~batch[\"ptx_mask\"]).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(ptx, ast_in, pad_mask)\n",
        "    pred = logits.argmax(dim=-1)\n",
        "    em_sum += exact_match_accuracy(pred, ast_tgt, ast_tok.pad_id, ast_tok.eos_id) * ptx.size(0)\n",
        "    ted_sum += compute_tree_edit_distance(pred, ast_tgt, ast_tok.pad_id, ast_tok.eos_id) * ptx.size(0)\n",
        "    n += ptx.size(0)\n",
        "    pbar.set_postfix(em=f\"{em_sum/n:.4f}\", ted=f\"{ted_sum/n:.4f}\")\n",
        "\n",
        "print(f\"\\nExact Match: {em_sum/n:.4f}\")\n",
        "print(f\"Tree Edit Sim: {ted_sum/n:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "compile_ok = compile_success_rate(\n",
        "    val_df[\"ast_sexp\"].head(100).tolist(),\n",
        "    render_fn=ast_to_cuda,\n",
        "    compile_fn=lambda cuda: compile_cuda_to_ptx_silent(cuda) is not None,\n",
        ")\n",
        "print(f\"Compilation success (on gold AST): {compile_ok:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "per_tier = val_df.groupby(\"tier\").agg({\"ast_sexp\": \"count\"}).rename(columns={\"ast_sexp\": \"count\"})\n",
        "print(per_tier)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}