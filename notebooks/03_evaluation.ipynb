{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Evaluation â€” 4-Axis Metrics & Attention Maps\n",
    "\n",
    "Load trained model and validation data. Compute exact match, tree edit similarity, compilation success, and plot attention heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"/content/Neural PTX Decompiler\" if os.path.exists(\"/content/Neural PTX Decompiler\") else \"..\"))\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from ptx_decompiler.model import PTXDecompilerModel\n",
    "from ptx_decompiler.tokenizer import PTXTokenizer, ASTTokenizer\n",
    "from ptx_decompiler.data import normalize_ptx, ast_to_cuda\n",
    "from ptx_decompiler.data.compiler import compile_cuda_to_ptx_silent\n",
    "from ptx_decompiler.training.metrics import exact_match_accuracy, compute_tree_edit_distance, compile_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/content/drive/MyDrive/NeuralPTX/dataset_100k.parquet\"\n",
    "CKPT_PATH = \"/content/drive/MyDrive/NeuralPTX/checkpoints/checkpoint_epoch_29.pt\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "ptx_tok = PTXTokenizer(max_vocab_size=2000)\n",
    "ptx_tok.build_vocab(df[\"ptx_normalized\"].tolist())\n",
    "ast_tok = ASTTokenizer()\n",
    "\n",
    "ptx_to_ast = torch.full((len(ptx_tok),), -1, dtype=torch.long)\n",
    "for t, pid in ptx_tok.vocab.items():\n",
    "    if t in ast_tok.vocab:\n",
    "        ptx_to_ast[pid] = ast_tok.vocab[t]\n",
    "\n",
    "model = PTXDecompilerModel(\n",
    "    ptx_vocab_size=len(ptx_tok),\n",
    "    ast_vocab_size=len(ast_tok),\n",
    "    ptx_to_ast_map=ptx_to_ast,\n",
    ").to(DEVICE)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptx_decompiler.data.dataset import PTXASTDataset, collate_pad_batch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_df = df.sample(frac=0.1, random_state=42)\n",
    "val_ds = PTXASTDataset(\n",
    "    ptx_strings=val_df[\"ptx_normalized\"].tolist(),\n",
    "    ast_strings=val_df[\"ast_sexp\"].tolist(),\n",
    "    ptx_tokenizer=ptx_tok,\n",
    "    ast_tokenizer=ast_tok,\n",
    "    tiers=val_df[\"tier\"].tolist(),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=64,\n",
    "    collate_fn=lambda b: collate_pad_batch(b, ptx_tok.pad_id, ast_tok.pad_id),\n",
    ")\n",
    "\n",
    "em_sum, ted_sum, n = 0.0, 0.0, 0\n",
    "for batch in val_loader:\n",
    "    ptx = batch[\"ptx_ids\"].to(DEVICE)\n",
    "    ast_in = batch[\"ast_input_ids\"].to(DEVICE)\n",
    "    ast_tgt = batch[\"ast_target_ids\"]\n",
    "    pad_mask = (~batch[\"ptx_mask\"]).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(ptx, ast_in, pad_mask)\n",
    "    pred = logits.argmax(dim=-1)\n",
    "    em_sum += exact_match_accuracy(pred, ast_tgt, ast_tok.pad_id, ast_tok.eos_id) * ptx.size(0)\n",
    "    ted_sum += compute_tree_edit_distance(pred, ast_tgt, ast_tok.pad_id, ast_tok.eos_id) * ptx.size(0)\n",
    "    n += ptx.size(0)\n",
    "print(f\"Exact Match: {em_sum/n:.4f}\")\n",
    "print(f\"Tree Edit Sim: {ted_sum/n:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compile_ok = compile_success_rate(\n",
    "    val_df[\"ast_sexp\"].head(100).tolist(),\n",
    "    render_fn=ast_to_cuda,\n",
    "    compile_fn=lambda cuda: compile_cuda_to_ptx_silent(cuda) is not None,\n",
    ")\n",
    "print(f\"Compilation success (on gold AST): {compile_ok:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_tier = val_df.groupby(\"tier\").agg({\"ast_sexp\": \"count\"}).rename(columns={\"ast_sexp\": \"count\"})\n",
    "print(per_tier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
