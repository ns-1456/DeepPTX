{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Evaluation — 4-Axis Metrics & Attention Maps\n",
    "\n",
    "Load trained model and validation data. Compute exact match, tree edit similarity,\n",
    "compilation success, and plot attention heatmaps.\n",
    "\n",
    "**Works on:** Colab (CUDA), Mac (MPS), or CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clone repo on Colab ---\n",
    "import os\n",
    "if os.path.exists(\"/content\") and not os.path.exists(\"/content/DeepPTX\"):\n",
    "    !git clone https://github.com/ns-1456/DeepPTX.git /content/DeepPTX\n",
    "    %cd /content/DeepPTX\n",
    "    !pip install -q tqdm pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "IN_COLAB = os.path.exists(\"/content\")\n",
    "REPO_ROOT = \"/content/DeepPTX\" if IN_COLAB else os.path.abspath(\"..\")\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from ptx_decompiler.utils import get_device\n",
    "from ptx_decompiler.model import PTXDecompilerModel\n",
    "from ptx_decompiler.tokenizer import PTXTokenizer, ASTTokenizer\n",
    "from ptx_decompiler.data import normalize_ptx, ast_to_cuda\n",
    "from ptx_decompiler.training.metrics import exact_match_accuracy, compute_tree_edit_distance, compile_success_rate\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================= Paths =======================\n",
    "if IN_COLAB:\n",
    "    DATA_PATH = os.path.join(REPO_ROOT, \"dataset_100k.parquet\")\n",
    "    CKPT_PATH = os.path.join(REPO_ROOT, \"checkpoints\", \"checkpoint_final.pt\")\n",
    "else:\n",
    "    DATA_PATH = os.path.join(REPO_ROOT, \"dataset_100k.parquet\")\n",
    "    CKPT_PATH = os.path.join(REPO_ROOT, \"checkpoints\", \"checkpoint_final.pt\")\n",
    "\n",
    "assert os.path.exists(DATA_PATH), f\"Dataset not found: {DATA_PATH}\"\n",
    "assert os.path.exists(CKPT_PATH), f\"Checkpoint not found: {CKPT_PATH}\"\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "print(f\"Loaded {len(df):,} samples\")\n",
    "\n",
    "ptx_tok = PTXTokenizer(max_vocab_size=2000)\n",
    "ptx_tok.build_vocab(df[\"ptx_normalized\"].tolist())\n",
    "ast_tok = ASTTokenizer()\n",
    "\n",
    "ptx_to_ast = torch.full((len(ptx_tok),), -1, dtype=torch.long)\n",
    "for t, pid in ptx_tok.vocab.items():\n",
    "    if t in ast_tok.vocab:\n",
    "        ptx_to_ast[pid] = ast_tok.vocab[t]\n",
    "\n",
    "model = PTXDecompilerModel(\n",
    "    ptx_vocab_size=len(ptx_tok),\n",
    "    ast_vocab_size=len(ast_tok),\n",
    "    ptx_to_ast_map=ptx_to_ast,\n",
    ").to(DEVICE)\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE, weights_only=True)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "print(f\"Model loaded from epoch {ckpt.get('epoch', '?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptx_decompiler.data.dataset import PTXASTDataset, collate_pad_batch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "val_df = df.sample(frac=0.1, random_state=42)\n",
    "val_ds = PTXASTDataset(\n",
    "    ptx_strings=val_df[\"ptx_normalized\"].tolist(),\n",
    "    ast_strings=val_df[\"ast_sexp\"].tolist(),\n",
    "    ptx_tokenizer=ptx_tok,\n",
    "    ast_tokenizer=ast_tok,\n",
    "    tiers=val_df[\"tier\"].tolist(),\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 64 if DEVICE.type == \"cuda\" else 32\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda b: collate_pad_batch(b, ptx_tok.pad_id, ast_tok.pad_id),\n",
    ")\n",
    "\n",
    "em_sum, ted_sum, n = 0.0, 0.0, 0\n",
    "pbar = tqdm(val_loader, desc=\"Evaluating\", unit=\"batch\",\n",
    "            bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] {postfix}\")\n",
    "for batch in pbar:\n",
    "    ptx = batch[\"ptx_ids\"].to(DEVICE)\n",
    "    ast_in = batch[\"ast_input_ids\"].to(DEVICE)\n",
    "    ast_tgt = batch[\"ast_target_ids\"]\n",
    "    pad_mask = (~batch[\"ptx_mask\"]).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(ptx, ast_in, pad_mask)\n",
    "    pred = logits.argmax(dim=-1).cpu()\n",
    "    em_sum += exact_match_accuracy(pred, ast_tgt, ast_tok.pad_id, ast_tok.eos_id) * ptx.size(0)\n",
    "    ted_sum += compute_tree_edit_distance(pred, ast_tgt, ast_tok.pad_id, ast_tok.eos_id) * ptx.size(0)\n",
    "    n += ptx.size(0)\n",
    "    pbar.set_postfix(em=f\"{em_sum/n:.4f}\", ted=f\"{ted_sum/n:.4f}\")\n",
    "\n",
    "print(f\"\\nExact Match: {em_sum/n:.4f}\")\n",
    "print(f\"Tree Edit Sim: {ted_sum/n:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation success rate (requires nvcc — skipped if not available)\n",
    "import shutil\n",
    "if shutil.which(\"nvcc\"):\n",
    "    from ptx_decompiler.data.compiler import compile_cuda_to_ptx_silent\n",
    "    compile_ok = compile_success_rate(\n",
    "        val_df[\"ast_sexp\"].head(100).tolist(),\n",
    "        render_fn=ast_to_cuda,\n",
    "        compile_fn=lambda cuda: compile_cuda_to_ptx_silent(cuda) is not None,\n",
    "    )\n",
    "    print(f\"Compilation success (on gold AST): {compile_ok:.4f}\")\n",
    "else:\n",
    "    print(\"nvcc not available — skipping compilation success rate.\")\n",
    "    print(\"(This metric is available on Colab or machines with CUDA toolkit)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-tier breakdown\n",
    "per_tier = val_df.groupby(\"tier\").agg({\"ast_sexp\": \"count\"}).rename(columns={\"ast_sexp\": \"count\"})\n",
    "print(per_tier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
