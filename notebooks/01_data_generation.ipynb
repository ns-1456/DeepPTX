{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Factory — Generate (PTX, AST, CUDA) Pairs\n",
        "\n",
        "**Important:** `nvcc` compilation is CPU-only (GPU does NOT help). Use a **CPU runtime** for this notebook to avoid wasting GPU credits. Switch to GPU runtime only for training (notebook 02).\n",
        "\n",
        "Strategy: batch-compile hundreds of `.cu` files at once with parallel `nvcc -O0`, reading all results back in bulk. This is 10-20x faster than sequential compilation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Run this cell first on Google Colab to clone the repo ---\n",
        "import os\n",
        "if not os.path.exists(\"/content/DeepPTX\"):\n",
        "    !git clone https://github.com/ns-1456/DeepPTX.git /content/DeepPTX\n",
        "%cd /content/DeepPTX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install deps and mount Drive (optional)\n",
        "\n",
        "In Colab: Runtime → Change runtime type → CPU is enough. Install `pyarrow` for Parquet. Optionally mount Google Drive to save the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q pyarrow tqdm\n",
        "\n",
        "# Optional: mount Google Drive to save the dataset persistently\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "# OUTPUT_DIR = \"/content/drive/MyDrive/NeuralPTX\"\n",
        "\n",
        "OUTPUT_DIR = \".\"  # saves to repo root; uncomment above for Drive\n",
        "\n",
        "# ============================================================\n",
        "# TARGET_PAIRS: start with 10k (~15 min). Scale to 100k later.\n",
        "# GPU does NOT help here -- nvcc is CPU-only.\n",
        "# Use a CPU runtime to avoid wasting GPU credits for this step.\n",
        "# ============================================================\n",
        "TARGET_PAIRS = 10_000\n",
        "COMPILE_BATCH = 200  # how many .cu files to write+compile per round"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add project root and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "# Add repo root to path (works both in Colab after clone, and locally from notebooks/)\n",
        "REPO_ROOT = \"/content/DeepPTX\" if os.path.exists(\"/content/DeepPTX\") else os.path.abspath(\"..\")\n",
        "if REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, REPO_ROOT)\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from ptx_decompiler.data import (\n",
        "    get_tier_generator,\n",
        "    TIER_WEIGHTS,\n",
        "    Tier1SimpleBinary,\n",
        "    Tier2NestedArithmetic,\n",
        "    Tier3UnaryMath,\n",
        "    Tier4Ternary,\n",
        "    Tier5TypeDiversity,\n",
        "    Tier6MultiStatement,\n",
        "    Tier7SharedMemory,\n",
        "    ast_to_cuda,\n",
        "    compile_cuda_to_ptx_silent,\n",
        "    normalize_ptx,\n",
        ")\n",
        "from ptx_decompiler.data.grammar import TIER_CLASSES, sample_tier\n",
        "print(\"Imports OK\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tempfile, subprocess, time, glob\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# =================================================================\n",
        "# BATCH compilation strategy:\n",
        "#   1. Generate N random ASTs + CUDA sources (instant, pure Python)\n",
        "#   2. Write all N .cu files to disk at once\n",
        "#   3. Compile ALL of them in one shot with GNU parallel / xargs\n",
        "#      (one nvcc per file, but OS schedules them across all cores)\n",
        "#   4. Read back .ptx files and normalize\n",
        "# This avoids Python subprocess overhead per file.\n",
        "# =================================================================\n",
        "\n",
        "WORK_DIR = tempfile.mkdtemp(prefix=\"ptx_batch_\")\n",
        "NUM_PARALLEL = max(os.cpu_count() or 2, 2) * 2  # parallel nvcc jobs\n",
        "print(f\"CPU cores: {os.cpu_count()} | Batch dir: {WORK_DIR}\")\n",
        "print(f\"Target: {TARGET_PAIRS} pairs | Batch size: {COMPILE_BATCH} | Parallel jobs: {NUM_PARALLEL}\")\n",
        "\n",
        "# Check if GNU parallel is available (faster than xargs)\n",
        "has_parallel = subprocess.run([\"which\", \"parallel\"], capture_output=True).returncode == 0\n",
        "print(f\"GNU parallel available: {has_parallel}\")\n",
        "\n",
        "def generate_batch_sources(n):\n",
        "    \"\"\"Generate n (ast_sexp, cuda_source, tier_id, score) tuples. Pure Python, instant.\"\"\"\n",
        "    batch = []\n",
        "    for _ in range(n):\n",
        "        tier_id, gen = sample_tier()\n",
        "        ast = gen.generate()\n",
        "        ast_sexp = ast.to_sexp()\n",
        "        cuda_source = ast_to_cuda(ast_sexp)\n",
        "        batch.append((ast_sexp, cuda_source, tier_id, gen.complexity_score))\n",
        "    return batch\n",
        "\n",
        "def write_cu_files(batch, work_dir):\n",
        "    \"\"\"Write .cu files to disk. Returns list of (index, ast_sexp, cuda_source, tier, score).\"\"\"\n",
        "    for i, (ast_sexp, cuda_source, tier_id, score) in enumerate(batch):\n",
        "        cu_path = Path(work_dir) / f\"{i}.cu\"\n",
        "        cu_path.write_text(cuda_source, encoding=\"utf-8\")\n",
        "    return batch\n",
        "\n",
        "def compile_all_cu(work_dir, n, num_parallel):\n",
        "    \"\"\"Compile all .cu -> .ptx in work_dir using xargs/parallel. Single OS call.\"\"\"\n",
        "    cu_files = [str(Path(work_dir) / f\"{i}.cu\") for i in range(n)]\n",
        "    cu_list = \"\\n\".join(cu_files)\n",
        "\n",
        "    if has_parallel:\n",
        "        cmd = f'echo \"{cu_list}\" | parallel -j {num_parallel} \"nvcc -ptx -O0 -arch=sm_75 {{}} -o {{.}}.ptx 2>/dev/null\"'\n",
        "    else:\n",
        "        # xargs fallback\n",
        "        cmd = f'echo \"{cu_list}\" | xargs -P {num_parallel} -I {{}} sh -c \\'nvcc -ptx -O0 -arch=sm_75 \"$1\" -o \"${{1%.cu}}.ptx\" 2>/dev/null\\' _ {{}}'\n",
        "\n",
        "    subprocess.run(cmd, shell=True, capture_output=True, timeout=300)\n",
        "\n",
        "def read_ptx_results(batch, work_dir):\n",
        "    \"\"\"Read .ptx files back, normalize, return completed rows.\"\"\"\n",
        "    results = []\n",
        "    for i, (ast_sexp, cuda_source, tier_id, score) in enumerate(batch):\n",
        "        ptx_path = Path(work_dir) / f\"{i}.ptx\"\n",
        "        if ptx_path.exists():\n",
        "            ptx_raw = ptx_path.read_text(encoding=\"utf-8\")\n",
        "            ptx_normalized = normalize_ptx(ptx_raw)\n",
        "            if ptx_normalized.strip():\n",
        "                results.append({\n",
        "                    \"ptx_normalized\": ptx_normalized,\n",
        "                    \"ast_sexp\": ast_sexp,\n",
        "                    \"cuda_source\": cuda_source,\n",
        "                    \"tier\": tier_id,\n",
        "                    \"complexity_score\": score,\n",
        "                })\n",
        "    return results\n",
        "\n",
        "def cleanup_batch(work_dir, n):\n",
        "    \"\"\"Remove .cu and .ptx files from the batch.\"\"\"\n",
        "    for i in range(n):\n",
        "        for ext in (\".cu\", \".ptx\"):\n",
        "            p = Path(work_dir) / f\"{i}{ext}\"\n",
        "            try:\n",
        "                p.unlink(missing_ok=True)\n",
        "            except OSError:\n",
        "                pass\n",
        "\n",
        "# ======================== Main generation loop ========================\n",
        "random.seed(42)\n",
        "data = []\n",
        "failures = 0\n",
        "round_num = 0\n",
        "\n",
        "pbar = tqdm(total=TARGET_PAIRS, desc=\"Generating pairs\", unit=\"pair\",\n",
        "            bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] fail={postfix}\")\n",
        "pbar.set_postfix_str(\"0\")\n",
        "\n",
        "while len(data) < TARGET_PAIRS:\n",
        "    round_num += 1\n",
        "    need = min(COMPILE_BATCH, int((TARGET_PAIRS - len(data)) * 1.2) + 10)\n",
        "\n",
        "    # Step 1: generate CUDA sources (instant)\n",
        "    batch = generate_batch_sources(need)\n",
        "\n",
        "    # Step 2: write .cu files\n",
        "    write_cu_files(batch, WORK_DIR)\n",
        "\n",
        "    # Step 3: compile all at once (one OS call, parallel nvcc)\n",
        "    compile_all_cu(WORK_DIR, len(batch), NUM_PARALLEL)\n",
        "\n",
        "    # Step 4: read results\n",
        "    results = read_ptx_results(batch, WORK_DIR)\n",
        "    batch_fails = len(batch) - len(results)\n",
        "    failures += batch_fails\n",
        "\n",
        "    for row in results:\n",
        "        if len(data) >= TARGET_PAIRS:\n",
        "            break\n",
        "        data.append(row)\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.set_postfix_str(str(failures))\n",
        "\n",
        "    # Step 5: cleanup\n",
        "    cleanup_batch(WORK_DIR, len(batch))\n",
        "\n",
        "pbar.close()\n",
        "total = len(data) + failures\n",
        "print(f\"\\nDone! {len(data)} pairs in {round_num} rounds\")\n",
        "print(f\"Compile failures: {failures} ({failures/max(total,1)*100:.1f}%)\")\n",
        "print(f\"Strategy: batch {COMPILE_BATCH} files x {NUM_PARALLEL} parallel nvcc (-O0)\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m max_attempts = TARGET_PAIRS * \u001b[32m3\u001b[39m  \u001b[38;5;66;03m# avoid infinite loop if compile fails often\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < TARGET_PAIRS \u001b[38;5;129;01mand\u001b[39;00m attempts < max_attempts:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     row = \u001b[43mgenerate_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     attempts += \u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgenerate_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m ast_sexp = ast.to_sexp()\n\u001b[32m      6\u001b[39m cuda_source = ast_to_cuda(ast_sexp)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m ptx_raw = \u001b[43mcompile_cuda_to_ptx_silent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ptx_raw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects for Resume/Neural PTX Decompiler/ptx_decompiler/data/compiler.py:55\u001b[39m, in \u001b[36mcompile_cuda_to_ptx_silent\u001b[39m\u001b[34m(cuda_source, work_dir)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_cuda_to_ptx_silent\u001b[39m(cuda_source: \u001b[38;5;28mstr\u001b[39m, work_dir: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     51\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    Compile CUDA to PTX; on success return PTX string, on failure return None.\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    Suppresses stderr from nvcc.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     ok, out = \u001b[43mcompile_cuda_to_ptx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;28;01mif\u001b[39;00m ok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects for Resume/Neural PTX Decompiler/ptx_decompiler/data/compiler.py:30\u001b[39m, in \u001b[36mcompile_cuda_to_ptx\u001b[39m\u001b[34m(cuda_source, work_dir, nvcc_path, arch)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     29\u001b[39m     cu_path.write_text(cuda_source, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnvcc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-ptx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-O3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-arch=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43march\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mptx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, result.stderr \u001b[38;5;129;01mor\u001b[39;00m result.stdout \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnvcc failed\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:1906\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1904\u001b[39m errpipe_data = \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[32m   1905\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1906\u001b[39m     part = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrpipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1907\u001b[39m     errpipe_data += part\n\u001b[32m   1908\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m part \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errpipe_data) > \u001b[32m50000\u001b[39m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save to Parquet and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.DataFrame(data)\n",
        "out_path = Path(OUTPUT_DIR) / \"dataset_100k.parquet\"\n",
        "df.to_parquet(out_path, index=False)\n",
        "print(f\"Saved to {out_path}\")\n",
        "print(df[\"tier\"].value_counts().sort_index())\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick validation: round-trip one row\n",
        "from ptx_decompiler.data import parse_sexp\n",
        "from ptx_decompiler.data.renderer import CUDARenderer\n",
        "\n",
        "r = df.iloc[0]\n",
        "tree = parse_sexp(r[\"ast_sexp\"])\n",
        "rendered = CUDARenderer().kernel_source(tree)\n",
        "assert r[\"cuda_source\"].strip() == rendered.strip(), \"Round-trip mismatch\"\n",
        "print(\"Round-trip OK.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}