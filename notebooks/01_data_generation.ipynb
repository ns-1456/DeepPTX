{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Factory — Generate 100k+ (PTX, AST, CUDA) Pairs\n",
        "\n",
        "Run this notebook in **Google Colab (Free tier)**. It uses the 7-tier grammar to generate random ASTs, renders them to CUDA, compiles with `nvcc` to PTX, and normalizes the PTX. Output is saved as Parquet for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Run this cell first on Google Colab to clone the repo ---\n",
        "import os\n",
        "if not os.path.exists(\"/content/DeepPTX\"):\n",
        "    !git clone https://github.com/ns-1456/DeepPTX.git /content/DeepPTX\n",
        "%cd /content/DeepPTX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install deps and mount Drive (optional)\n",
        "\n",
        "In Colab: Runtime → Change runtime type → CPU is enough. Install `pyarrow` for Parquet. Optionally mount Google Drive to save the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q pyarrow tqdm\n",
        "\n",
        "# Optional: mount Google Drive to save the dataset persistently\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "# OUTPUT_DIR = \"/content/drive/MyDrive/NeuralPTX\"\n",
        "\n",
        "OUTPUT_DIR = \".\"  # saves to repo root; uncomment above for Drive\n",
        "TARGET_PAIRS = 100_000\n",
        "BATCH_SIZE = 5000  # save progress every N pairs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add project root and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "# Add repo root to path (works both in Colab after clone, and locally from notebooks/)\n",
        "REPO_ROOT = \"/content/DeepPTX\" if os.path.exists(\"/content/DeepPTX\") else os.path.abspath(\"..\")\n",
        "if REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, REPO_ROOT)\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from ptx_decompiler.data import (\n",
        "    get_tier_generator,\n",
        "    TIER_WEIGHTS,\n",
        "    Tier1SimpleBinary,\n",
        "    Tier2NestedArithmetic,\n",
        "    Tier3UnaryMath,\n",
        "    Tier4Ternary,\n",
        "    Tier5TypeDiversity,\n",
        "    Tier6MultiStatement,\n",
        "    Tier7SharedMemory,\n",
        "    ast_to_cuda,\n",
        "    compile_cuda_to_ptx_silent,\n",
        "    normalize_ptx,\n",
        ")\n",
        "from ptx_decompiler.data.grammar import TIER_CLASSES, sample_tier\n",
        "print(\"Imports OK\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def generate_one():\n",
        "    \"\"\"Sample tier, generate AST, render CUDA, compile to PTX, normalize. Returns dict or None on compile failure.\"\"\"\n",
        "    tier_id, gen = sample_tier()\n",
        "    ast = gen.generate()\n",
        "    ast_sexp = ast.to_sexp()\n",
        "    cuda_source = ast_to_cuda(ast_sexp)\n",
        "    ptx_raw = compile_cuda_to_ptx_silent(cuda_source)\n",
        "    if ptx_raw is None:\n",
        "        return None\n",
        "    ptx_normalized = normalize_ptx(ptx_raw)\n",
        "    return {\n",
        "        \"ptx_normalized\": ptx_normalized,\n",
        "        \"ast_sexp\": ast_sexp,\n",
        "        \"cuda_source\": cuda_source,\n",
        "        \"tier\": tier_id,\n",
        "        \"complexity_score\": gen.complexity_score,\n",
        "    }\n",
        "\n",
        "random.seed(42)\n",
        "data = []\n",
        "attempts = 0\n",
        "failures = 0\n",
        "max_attempts = TARGET_PAIRS * 3\n",
        "\n",
        "pbar = tqdm(total=TARGET_PAIRS, desc=\"Generating pairs\", unit=\"pair\",\n",
        "            bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] failures={postfix}\")\n",
        "pbar.set_postfix_str(f\"0\")\n",
        "\n",
        "while len(data) < TARGET_PAIRS and attempts < max_attempts:\n",
        "    row = generate_one()\n",
        "    attempts += 1\n",
        "    if row is not None:\n",
        "        data.append(row)\n",
        "        pbar.update(1)\n",
        "        if len(data) % 500 == 0:\n",
        "            pbar.set_postfix_str(f\"{failures}\")\n",
        "    else:\n",
        "        failures += 1\n",
        "\n",
        "pbar.close()\n",
        "print(f\"\\nDone. Total pairs: {len(data)} | Attempts: {attempts} | Compile failures: {failures} ({failures/max(attempts,1)*100:.1f}%)\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m max_attempts = TARGET_PAIRS * \u001b[32m3\u001b[39m  \u001b[38;5;66;03m# avoid infinite loop if compile fails often\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < TARGET_PAIRS \u001b[38;5;129;01mand\u001b[39;00m attempts < max_attempts:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     row = \u001b[43mgenerate_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     attempts += \u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgenerate_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m ast_sexp = ast.to_sexp()\n\u001b[32m      6\u001b[39m cuda_source = ast_to_cuda(ast_sexp)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m ptx_raw = \u001b[43mcompile_cuda_to_ptx_silent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ptx_raw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects for Resume/Neural PTX Decompiler/ptx_decompiler/data/compiler.py:55\u001b[39m, in \u001b[36mcompile_cuda_to_ptx_silent\u001b[39m\u001b[34m(cuda_source, work_dir)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_cuda_to_ptx_silent\u001b[39m(cuda_source: \u001b[38;5;28mstr\u001b[39m, work_dir: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     51\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    Compile CUDA to PTX; on success return PTX string, on failure return None.\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    Suppresses stderr from nvcc.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     ok, out = \u001b[43mcompile_cuda_to_ptx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;28;01mif\u001b[39;00m ok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects for Resume/Neural PTX Decompiler/ptx_decompiler/data/compiler.py:30\u001b[39m, in \u001b[36mcompile_cuda_to_ptx\u001b[39m\u001b[34m(cuda_source, work_dir, nvcc_path, arch)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     29\u001b[39m     cu_path.write_text(cuda_source, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnvcc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-ptx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-O3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-arch=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43march\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mptx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, result.stderr \u001b[38;5;129;01mor\u001b[39;00m result.stdout \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnvcc failed\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:1906\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1904\u001b[39m errpipe_data = \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[32m   1905\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1906\u001b[39m     part = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrpipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1907\u001b[39m     errpipe_data += part\n\u001b[32m   1908\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m part \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errpipe_data) > \u001b[32m50000\u001b[39m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save to Parquet and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.DataFrame(data)\n",
        "out_path = Path(OUTPUT_DIR) / \"dataset_100k.parquet\"\n",
        "df.to_parquet(out_path, index=False)\n",
        "print(f\"Saved to {out_path}\")\n",
        "print(df[\"tier\"].value_counts().sort_index())\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick validation: round-trip one row\n",
        "from ptx_decompiler.data import parse_sexp\n",
        "from ptx_decompiler.data.renderer import CUDARenderer\n",
        "\n",
        "r = df.iloc[0]\n",
        "tree = parse_sexp(r[\"ast_sexp\"])\n",
        "rendered = CUDARenderer().kernel_source(tree)\n",
        "assert r[\"cuda_source\"].strip() == rendered.strip(), \"Round-trip mismatch\"\n",
        "print(\"Round-trip OK.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}