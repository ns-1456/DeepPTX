{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Data Factory — Generate (PTX, AST, CUDA) Pairs\n",
        "\n",
        "**Important:** `nvcc` compilation is CPU-only (GPU does NOT help). Use a **CPU runtime** for this notebook to avoid wasting GPU credits. Switch to GPU runtime only for training (notebook 02).\n",
        "\n",
        "Strategy: batch-compile hundreds of `.cu` files at once with parallel `nvcc -O0`, reading all results back in bulk. This is 10-20x faster than sequential compilation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Run this cell first on Google Colab to clone the repo ---\n",
        "import os\n",
        "if not os.path.exists(\"/content/DeepPTX\"):\n",
        "    !git clone https://github.com/ns-1456/DeepPTX.git /content/DeepPTX\n",
        "%cd /content/DeepPTX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Install deps and mount Drive (optional)\n",
        "\n",
        "In Colab: Runtime → Change runtime type → CPU is enough. Install `pyarrow` for Parquet. Optionally mount Google Drive to save the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install -q pyarrow tqdm\n",
        "\n",
        "# Optional: mount Google Drive to save the dataset persistently\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "# OUTPUT_DIR = \"/content/drive/MyDrive/NeuralPTX\"\n",
        "\n",
        "OUTPUT_DIR = \".\"  # saves to repo root; uncomment above for Drive\n",
        "\n",
        "# ============================================================\n",
        "# TARGET_PAIRS: start with 10k (~15 min). Scale to 100k later.\n",
        "# GPU does NOT help here -- nvcc is CPU-only.\n",
        "# Use a CPU runtime to avoid wasting GPU credits for this step.\n",
        "# ============================================================\n",
        "TARGET_PAIRS = 10_000\n",
        "COMPILE_BATCH = 200  # how many .cu files to write+compile per round"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add project root and import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "# Add repo root to path (works both in Colab after clone, and locally from notebooks/)\n",
        "REPO_ROOT = \"/content/DeepPTX\" if os.path.exists(\"/content/DeepPTX\") else os.path.abspath(\"..\")\n",
        "if REPO_ROOT not in sys.path:\n",
        "    sys.path.insert(0, REPO_ROOT)\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from ptx_decompiler.data import (\n",
        "    get_tier_generator,\n",
        "    TIER_WEIGHTS,\n",
        "    Tier1SimpleBinary,\n",
        "    Tier2NestedArithmetic,\n",
        "    Tier3UnaryMath,\n",
        "    Tier4Ternary,\n",
        "    Tier5TypeDiversity,\n",
        "    Tier6MultiStatement,\n",
        "    Tier7SharedMemory,\n",
        "    ast_to_cuda,\n",
        "    compile_cuda_to_ptx_silent,\n",
        "    normalize_ptx,\n",
        ")\n",
        "from ptx_decompiler.data.grammar import TIER_CLASSES, sample_tier\n",
        "print(\"Imports OK\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import tempfile, subprocess, time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# =================================================================\n",
        "# Strategy: fire N nvcc processes at once using subprocess.Popen\n",
        "# (no shell piping, no xargs, no GNU parallel -- just direct calls)\n",
        "# Then wait for all to finish and read results.\n",
        "# -O0 = skip optimization (3x faster per file).\n",
        "# =================================================================\n",
        "\n",
        "WORK_DIR = tempfile.mkdtemp(prefix=\"ptx_batch_\")\n",
        "NUM_PARALLEL = max(os.cpu_count() or 2, 2) * 3  # e.g. 2 cores -> 6 simultaneous nvcc\n",
        "print(f\"CPU cores: {os.cpu_count()} | Parallel nvcc: {NUM_PARALLEL}\")\n",
        "print(f\"Target: {TARGET_PAIRS} pairs | Batch size: {COMPILE_BATCH}\")\n",
        "\n",
        "# ---- Quick sanity check: can nvcc compile anything at all? ----\n",
        "test_cu = Path(WORK_DIR) / \"test.cu\"\n",
        "test_ptx = Path(WORK_DIR) / \"test.ptx\"\n",
        "test_cu.write_text('extern \"C\" __global__ void k(float* a) { a[0] = 1.0f; }')\n",
        "r = subprocess.run([\"nvcc\", \"-ptx\", \"-O0\", str(test_cu), \"-o\", str(test_ptx)],\n",
        "                    capture_output=True, text=True, timeout=30)\n",
        "if r.returncode != 0:\n",
        "    print(f\"ERROR: nvcc sanity check failed!\\nstderr: {r.stderr}\\nstdout: {r.stdout}\")\n",
        "    # Try without -arch flag\n",
        "    r2 = subprocess.run([\"nvcc\", \"-ptx\", \"-O0\", str(test_cu), \"-o\", str(test_ptx)],\n",
        "                        capture_output=True, text=True, timeout=30)\n",
        "    print(f\"Without -arch: returncode={r2.returncode}\")\n",
        "else:\n",
        "    print(f\"nvcc sanity check OK ({test_ptx.stat().st_size} bytes)\")\n",
        "test_cu.unlink(missing_ok=True)\n",
        "test_ptx.unlink(missing_ok=True)\n",
        "\n",
        "# Detect correct arch: try sm_75 (T4), fallback to no arch flag\n",
        "NVCC_ARCH = []\n",
        "test_cu.write_text('extern \"C\" __global__ void k(float* a) { a[0] = 1.0f; }')\n",
        "r = subprocess.run([\"nvcc\", \"-ptx\", \"-O0\", \"-arch=sm_75\", str(test_cu), \"-o\", str(test_ptx)],\n",
        "                    capture_output=True, text=True, timeout=30)\n",
        "if r.returncode == 0:\n",
        "    NVCC_ARCH = [\"-arch=sm_75\"]\n",
        "    print(\"Using -arch=sm_75 (T4)\")\n",
        "else:\n",
        "    print(\"Using default arch (no -arch flag)\")\n",
        "test_cu.unlink(missing_ok=True)\n",
        "test_ptx.unlink(missing_ok=True)\n",
        "\n",
        "def generate_batch_sources(n):\n",
        "    \"\"\"Generate n (ast_sexp, cuda_source, tier_id, score) tuples. Pure Python, instant.\"\"\"\n",
        "    batch = []\n",
        "    for _ in range(n):\n",
        "        tier_id, gen = sample_tier()\n",
        "        ast = gen.generate()\n",
        "        ast_sexp = ast.to_sexp()\n",
        "        cuda_source = ast_to_cuda(ast_sexp)\n",
        "        batch.append((ast_sexp, cuda_source, tier_id, gen.complexity_score))\n",
        "    return batch\n",
        "\n",
        "def compile_batch_parallel(batch, work_dir, max_concurrent):\n",
        "    \"\"\"\n",
        "    Write .cu files, fire max_concurrent nvcc processes at once,\n",
        "    wait for all, read .ptx results. No shell piping.\n",
        "    \"\"\"\n",
        "    n = len(batch)\n",
        "    cu_paths = []\n",
        "    ptx_paths = []\n",
        "\n",
        "    # Write all .cu files\n",
        "    for i, (_, cuda_src, _, _) in enumerate(batch):\n",
        "        cu = Path(work_dir) / f\"{i}.cu\"\n",
        "        ptx = Path(work_dir) / f\"{i}.ptx\"\n",
        "        cu.write_text(cuda_src, encoding=\"utf-8\")\n",
        "        cu_paths.append(cu)\n",
        "        ptx_paths.append(ptx)\n",
        "\n",
        "    # Fire nvcc processes in waves of max_concurrent\n",
        "    processes = [None] * n\n",
        "    for start in range(0, n, max_concurrent):\n",
        "        end = min(start + max_concurrent, n)\n",
        "        procs = []\n",
        "        for i in range(start, end):\n",
        "            cmd = [\"nvcc\", \"-ptx\", \"-O0\"] + NVCC_ARCH + [str(cu_paths[i]), \"-o\", str(ptx_paths[i])]\n",
        "            p = subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            procs.append((i, p))\n",
        "        # Wait for this wave\n",
        "        for i, p in procs:\n",
        "            try:\n",
        "                p.wait(timeout=30)\n",
        "            except subprocess.TimeoutExpired:\n",
        "                p.kill()\n",
        "\n",
        "    # Read results\n",
        "    results = []\n",
        "    for i, (ast_sexp, cuda_src, tier_id, score) in enumerate(batch):\n",
        "        if ptx_paths[i].exists() and ptx_paths[i].stat().st_size > 0:\n",
        "            ptx_raw = ptx_paths[i].read_text(encoding=\"utf-8\")\n",
        "            ptx_norm = normalize_ptx(ptx_raw)\n",
        "            if ptx_norm.strip():\n",
        "                results.append({\n",
        "                    \"ptx_normalized\": ptx_norm,\n",
        "                    \"ast_sexp\": ast_sexp,\n",
        "                    \"cuda_source\": cuda_src,\n",
        "                    \"tier\": tier_id,\n",
        "                    \"complexity_score\": score,\n",
        "                })\n",
        "        # Cleanup\n",
        "        cu_paths[i].unlink(missing_ok=True)\n",
        "        ptx_paths[i].unlink(missing_ok=True)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ======================== Main loop ========================\n",
        "random.seed(42)\n",
        "data = []\n",
        "failures = 0\n",
        "round_num = 0\n",
        "\n",
        "pbar = tqdm(total=TARGET_PAIRS, desc=\"Generating pairs\", unit=\"pair\",\n",
        "            bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] fail={postfix}\")\n",
        "pbar.set_postfix_str(\"0\")\n",
        "\n",
        "while len(data) < TARGET_PAIRS:\n",
        "    round_num += 1\n",
        "    need = min(COMPILE_BATCH, int((TARGET_PAIRS - len(data)) * 1.15) + 10)\n",
        "\n",
        "    batch = generate_batch_sources(need)\n",
        "    results = compile_batch_parallel(batch, WORK_DIR, NUM_PARALLEL)\n",
        "\n",
        "    batch_fails = len(batch) - len(results)\n",
        "    failures += batch_fails\n",
        "\n",
        "    for row in results:\n",
        "        if len(data) >= TARGET_PAIRS:\n",
        "            break\n",
        "        data.append(row)\n",
        "    pbar.n = len(data)\n",
        "    pbar.set_postfix_str(str(failures))\n",
        "    pbar.refresh()\n",
        "\n",
        "pbar.close()\n",
        "total = len(data) + failures\n",
        "rate = len(data) / max(1, pbar.format_dict.get(\"elapsed\", 1))\n",
        "print(f\"\\nDone! {len(data)} pairs in {round_num} rounds\")\n",
        "print(f\"Compile failures: {failures} ({failures/max(total,1)*100:.1f}%)\")\n",
        "print(f\"Effective rate: {rate:.1f} pairs/sec ({NUM_PARALLEL} parallel nvcc, -O0)\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m max_attempts = TARGET_PAIRS * \u001b[32m3\u001b[39m  \u001b[38;5;66;03m# avoid infinite loop if compile fails often\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < TARGET_PAIRS \u001b[38;5;129;01mand\u001b[39;00m attempts < max_attempts:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     row = \u001b[43mgenerate_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     attempts += \u001b[32m1\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mgenerate_one\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      5\u001b[39m ast_sexp = ast.to_sexp()\n\u001b[32m      6\u001b[39m cuda_source = ast_to_cuda(ast_sexp)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m ptx_raw = \u001b[43mcompile_cuda_to_ptx_silent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ptx_raw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects for Resume/Neural PTX Decompiler/ptx_decompiler/data/compiler.py:55\u001b[39m, in \u001b[36mcompile_cuda_to_ptx_silent\u001b[39m\u001b[34m(cuda_source, work_dir)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_cuda_to_ptx_silent\u001b[39m(cuda_source: \u001b[38;5;28mstr\u001b[39m, work_dir: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     51\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m    Compile CUDA to PTX; on success return PTX string, on failure return None.\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    Suppresses stderr from nvcc.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     ok, out = \u001b[43mcompile_cuda_to_ptx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcuda_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;28;01mif\u001b[39;00m ok \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Projects for Resume/Neural PTX Decompiler/ptx_decompiler/data/compiler.py:30\u001b[39m, in \u001b[36mcompile_cuda_to_ptx\u001b[39m\u001b[34m(cuda_source, work_dir, nvcc_path, arch)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     29\u001b[39m     cu_path.write_text(cuda_source, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnvcc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-ptx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-O3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-arch=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43march\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcu_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-o\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mptx_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, result.stderr \u001b[38;5;129;01mor\u001b[39;00m result.stdout \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnvcc failed\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    546\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    550\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/subprocess.py:1906\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1904\u001b[39m errpipe_data = \u001b[38;5;28mbytearray\u001b[39m()\n\u001b[32m   1905\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1906\u001b[39m     part = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrpipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1907\u001b[39m     errpipe_data += part\n\u001b[32m   1908\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m part \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errpipe_data) > \u001b[32m50000\u001b[39m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save to Parquet and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.DataFrame(data)\n",
        "out_path = Path(OUTPUT_DIR) / \"dataset_100k.parquet\"\n",
        "df.to_parquet(out_path, index=False)\n",
        "print(f\"Saved to {out_path}\")\n",
        "print(df[\"tier\"].value_counts().sort_index())\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick validation: round-trip one row\n",
        "from ptx_decompiler.data import parse_sexp\n",
        "from ptx_decompiler.data.renderer import CUDARenderer\n",
        "\n",
        "r = df.iloc[0]\n",
        "tree = parse_sexp(r[\"ast_sexp\"])\n",
        "rendered = CUDARenderer().kernel_source(tree)\n",
        "assert r[\"cuda_source\"].strip() == rendered.strip(), \"Round-trip mismatch\"\n",
        "print(\"Round-trip OK.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}